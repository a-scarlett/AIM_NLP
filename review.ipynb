{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Overview",
   "id": "932f3f08e1656c86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "В этом репо я хочу создать классификатор для командной строки, который бы умел реагировать на ввод не bash команды, а nl. Для этого я сначала создам датасет для эвала и тренировки, выберу метрики и подходящие архитектуры. Потом мы сравним точность и скорость полученных моделей.",
   "id": "5268882aa08390ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Создание датасета",
   "id": "9a49cf79c77b270f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Используемые датасеты (подробный код в data_preprocessing):\n",
    " - [NL2Bash](https://arxiv.org/abs/1802.08979), разделив отдельно команды и их описание, получим 10347 пар.\n",
    " - [NLC2CMD](https://arxiv.org/abs/2302.07845) - расширение для NL2Bash, но сильно загрязненное, с меньшим разнообразием команд. По итогу выгоднее не брать.\n",
    "- bash history из [Cybersecurity Training](https://gitlab.ics.muni.cz/muni-kypo-trainings/datasets/commands), используем немного для разнообразия.\n",
    "- synthetic data, сгенерированные с помощью gpt-4o 375 сложных описаний которые используют внутри себя сами команды или флаги к ним."
   ],
   "id": "40370903bdb9b2b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "В тестовом датасете мы считаем, что соотношение 9:1 между bash и nl наиболее точно отображает реальное. Также стараемся максимально возможно сбалансировать датасет по разнообразию команд. После этого в NL2Bash мы из выбранных пар случайным образом берем nl/bash пример для тестового датасета",
   "id": "a30badb33109f1ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Метрики",
   "id": "ce398b981c11f0e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "В качестве метрики нам наиболее интересен Recall, поскольку ложное срабатывание классификатора будет запускать следующую модель и приносить неудобство. Но мы также будет измерять F1, ROC AUC (данные сильно не сбалансированы), Precision.",
   "id": "d2a59182964bef09"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Архитектуры",
   "id": "e57df054cda74479"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Наиболее подходящими для этой задачи являются bert подобные модели и catboost.",
   "id": "ded417f06c9ddd0e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Distilbert",
   "id": "b5054c833d6ef39b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Как видно в \"disilbert.ipynb\" к концу первой эпохи уже имел >0.99 по F1, ROC AUC, Recall, Precision.\n",
    "Плюсы: не требует feature extraction\n",
    "Минусы: Медленный (увидим во время сравнения с catboost)"
   ],
   "id": "3bd37360756f4ddb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d952584c6d5fa8a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
