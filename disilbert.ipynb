{
 "cells": [
  {
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "88f0356435f94331af56c82eab200f07",
      "619c05fe69744cbfbe1e77372b96c276",
      "25d5f2514b3641cfb6b9e18a376099e2",
      "74998074f8254974934421cba03db4dd",
      "1dd8fefe36dc43b0aa36fdb4f0c98d82",
      "2e1a5250fcb04d3287cda92e9a26c8c1",
      "ec30b7119107455d83d2564e32bb0c97",
      "43fe62ae6dad473ebb6f11c5fab53133",
      "b2c096a686c44018898349717aa369b3"
     ]
    },
    "id": "717182e88b03750e",
    "outputId": "70172068-96db-49d3-8712-f0ab704b0b9e",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-25T21:50:42.695311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import (\n",
    "    logging, set_seed, DataCollatorWithPadding, Trainer, TrainerCallback, TrainerState, TrainerControl,\n",
    "    TrainingArguments, DistilBertTokenizer, DistilBertConfig, DistilBertForSequenceClassification\n",
    ")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import f1_score, roc_auc_score, recall_score, accuracy_score\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else\n",
    "                      \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.model_name_or_path = \"distilbert-base-uncased\"\n",
    "        self.tokenizer= DistilBertTokenizer.from_pretrained(self.model_name_or_path )\n",
    "        self.max_seq_length = 512\n",
    "        self.learning_rate = 2e-5\n",
    "        self.num_epochs = 2\n",
    "        self.per_gpu_batch_size = 16\n",
    "        self.seed = 42\n",
    "        self.output_dir = \"./results\"\n",
    "        self.gradient_accumulation_steps = 1\n",
    "        self.lr_scheduler_type = \"linear\"\n",
    "        self.num_warmup_steps = 0\n",
    "        self.weight_decay = 0.1\n",
    "        self.push_to_hub = True\n",
    "        self.model_hub_name = \"a-scarlett/NLCvsBash\"\n",
    "        self.warmup_ratio = 0\n",
    "        self.max_grad_norm = 1.0\n",
    "        self.dropout_rate = 0.4\n",
    "        self.save_steps = 100\n",
    "        self.eval_steps = 100\n",
    "        self.logging_steps = 10\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "    if predictions.shape[1] > 1:\n",
    "        one_hot_labels = np.eye(predictions.shape[1])[labels]\n",
    "        roc_auc = roc_auc_score(one_hot_labels, predictions, multi_class='ovr', average='weighted')\n",
    "    else:\n",
    "        roc_auc = roc_auc_score(labels, predictions[:, 1])\n",
    "\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "\n",
    "    return {\n",
    "        \"f1\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"recall\": recall,\n",
    "        \"roc_auc\": roc_auc\n",
    "    }\n",
    "\n",
    "def preprocess_function(examples, tokenizer, max_seq_length):\n",
    "   tokenized_examples = tokenizer(\n",
    "       examples['value'],\n",
    "       padding=\"max_length\",\n",
    "       truncation=True,\n",
    "       max_length=max_seq_length\n",
    "   )\n",
    "   tokenized_examples['labels'] = examples['target']\n",
    "   return tokenized_examples\n",
    "\n",
    "def load_csv_as_dataset(train_path, test_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    # Ensure the data has 'text' and 'label' columns\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "    # Create a DatasetDict\n",
    "    dataset = DatasetDict({\n",
    "        'train': train_dataset,\n",
    "        'test': test_dataset\n",
    "    })\n",
    "\n",
    "    return dataset\n",
    "\n",
    "class CustomCallback(TrainerCallback):\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.epochs = []\n",
    "        self.texts = []\n",
    "        self.predictions = []\n",
    "        self.labels = []\n",
    "\n",
    "    def on_evaluate(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        if state.is_world_process_zero:\n",
    "            eval_dataloader = kwargs[\"eval_dataloader\"]\n",
    "            model = kwargs[\"model\"]\n",
    "\n",
    "            for batch in eval_dataloader:\n",
    "                inputs = batch['input_ids'].to(model.device)\n",
    "                attention_mask = batch['attention_mask'].to(model.device)\n",
    "                labels = batch['labels'].cpu().numpy()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(input_ids=inputs, attention_mask=attention_mask)\n",
    "                    preds = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "                decoded_texts = self.tokenizer.batch_decode(inputs, skip_special_tokens=True)\n",
    "\n",
    "                for i in range(min(10, len(preds))):\n",
    "                    self.epochs.append(state.epoch)\n",
    "                    self.texts.append(decoded_texts[i])\n",
    "                    self.predictions.append(preds[i])\n",
    "                    self.labels.append(labels[i])\n",
    "\n",
    "                break\n",
    "\n",
    "    def on_train_end(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(self.epochs, self.labels, 'bo-', label='Labels')\n",
    "        ax.plot(self.epochs, self.predictions, 'ro-', label='Predictions')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Label/Predictions')\n",
    "        ax.legend(loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "class MetricsLoggerCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.metrics = []\n",
    "\n",
    "    def on_evaluate(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        if state.is_world_process_zero and \"eval_predictions\" in kwargs:\n",
    "            predictions = kwargs[\"eval_predictions\"].predictions\n",
    "            labels = kwargs[\"eval_predictions\"].label_ids\n",
    "\n",
    "            if predictions.shape[-1] > 1:\n",
    "                predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "            metrics = compute_metrics((predictions, labels))\n",
    "            self.metrics.append(metrics)\n",
    "\n",
    "    def on_train_end(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        epochs = list(range(1, len(self.metrics) + 1))\n",
    "\n",
    "        f1_scores = [metric['f1'] for metric in self.metrics]\n",
    "        accuracies = [metric['accuracy'] for metric in self.metrics]\n",
    "        recalls = [metric['recall'] for metric in self.metrics]\n",
    "        roc_aucs = [metric['roc_auc'] for metric in self.metrics]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(epochs, f1_scores, label='F1 Score', marker='o')\n",
    "        plt.plot(epochs, accuracies, label='Accuracy', marker='x')\n",
    "        plt.plot(epochs, recalls, label='Recall', marker='s')\n",
    "        plt.plot(epochs, roc_aucs, label='ROC AUC', marker='d')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Metric Score')\n",
    "        plt.legend()\n",
    "        plt.title('Evaluation Metrics Over Epochs')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = Args()\n",
    "    set_seed(args.seed)\n",
    "\n",
    "    train_csv_path = \"data/train.csv\"\n",
    "    test_csv_path = \"data/test.csv\"\n",
    "\n",
    "    dataset = load_csv_as_dataset(train_csv_path, test_csv_path)\n",
    "\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(args.model_name_or_path)\n",
    "\n",
    "    tokenized_dataset = dataset.map(\n",
    "        lambda x: preprocess_function(x, tokenizer, args.max_seq_length),\n",
    "        batched=True\n",
    "    )\n",
    "\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(args.model_name_or_path, num_labels=2).to(device)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=args.output_dir,\n",
    "        learning_rate=args.learning_rate,\n",
    "        lr_scheduler_type=args.lr_scheduler_type,\n",
    "        warmup_ratio=args.warmup_ratio,\n",
    "        eval_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        eval_steps=args.eval_steps,\n",
    "        save_steps=args.save_steps,\n",
    "        logging_steps=args.logging_steps,\n",
    "        per_device_train_batch_size=args.per_gpu_batch_size,\n",
    "        per_device_eval_batch_size=args.per_gpu_batch_size,\n",
    "        num_train_epochs=args.num_epochs,\n",
    "        gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
    "        weight_decay=args.weight_decay,\n",
    "        save_total_limit=2,\n",
    "        metric_for_best_model='f1',\n",
    "        load_best_model_at_end=True,\n",
    "        run_name=\"NLC2CMD\",\n",
    "        # report_to=\"wandb\",\n",
    "        max_grad_norm=args.max_grad_norm,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[MetricsLoggerCallback(), CustomCallback(tokenizer)]\n",
    "    )\n",
    "\n",
    "    trainer.evaluate()\n",
    "    print(\"Training...\")\n",
    "    trainer.train()\n",
    "\n",
    "    if args.push_to_hub:\n",
    "        model.push_to_hub(args.model_hub_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "717182e88b03750e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/11528 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42732da9475c4ff3a9a582ce5384b569"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/5133 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0d411a09cd4442d8230d71757f3a946"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/6dz6d3kx3dbbnjwnn7bh885r0000gp/T/ipykernel_27597/1667845250.py:210: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6507952213287354, 'eval_model_preparation_time': 0.0006, 'eval_f1': 0.8597473736074243, 'eval_accuracy': 0.8988895382817066, 'eval_recall': 0.8988895382817066, 'eval_roc_auc': 0.7268220261731206, 'eval_runtime': 209.0813, 'eval_samples_per_second': 24.55, 'eval_steps_per_second': 1.535}\n",
      "Training...\n",
      "{'loss': 0.4148, 'grad_norm': 1.8826617002487183, 'learning_rate': 1.9861303744798893e-05, 'epoch': 0.013869625520110958}\n",
      "{'loss': 0.3033, 'grad_norm': 1.9901610612869263, 'learning_rate': 1.9722607489597782e-05, 'epoch': 0.027739251040221916}\n",
      "{'loss': 0.1992, 'grad_norm': 1.9535813331604004, 'learning_rate': 1.9583911234396674e-05, 'epoch': 0.04160887656033287}\n",
      "{'loss': 0.122, 'grad_norm': 1.777485728263855, 'learning_rate': 1.9445214979195562e-05, 'epoch': 0.05547850208044383}\n",
      "{'loss': 0.1498, 'grad_norm': 0.4365811347961426, 'learning_rate': 1.9306518723994454e-05, 'epoch': 0.06934812760055478}\n",
      "{'loss': 0.0617, 'grad_norm': 0.14014537632465363, 'learning_rate': 1.9167822468793346e-05, 'epoch': 0.08321775312066575}\n",
      "{'loss': 0.063, 'grad_norm': 0.5810226798057556, 'learning_rate': 1.9029126213592234e-05, 'epoch': 0.0970873786407767}\n",
      "{'loss': 0.0405, 'grad_norm': 0.6624870300292969, 'learning_rate': 1.8890429958391126e-05, 'epoch': 0.11095700416088766}\n",
      "{'loss': 0.0221, 'grad_norm': 0.44842496514320374, 'learning_rate': 1.8751733703190014e-05, 'epoch': 0.12482662968099861}\n",
      "{'loss': 0.0125, 'grad_norm': 0.10066723078489304, 'learning_rate': 1.8613037447988906e-05, 'epoch': 0.13869625520110956}\n",
      "{'eval_loss': 0.021590959280729294, 'eval_model_preparation_time': 0.0006, 'eval_f1': 0.9934380834509627, 'eval_accuracy': 0.9933761932593026, 'eval_recall': 0.9933761932593026, 'eval_roc_auc': 0.9994070741253706, 'eval_runtime': 239.3322, 'eval_samples_per_second': 21.447, 'eval_steps_per_second': 1.341, 'epoch': 0.13869625520110956}\n",
      "{'loss': 0.0064, 'grad_norm': 0.12758730351924896, 'learning_rate': 1.8474341192787798e-05, 'epoch': 0.15256588072122051}\n",
      "{'loss': 0.0108, 'grad_norm': 0.07056981325149536, 'learning_rate': 1.8335644937586686e-05, 'epoch': 0.1664355062413315}\n",
      "{'loss': 0.0139, 'grad_norm': 0.04445955157279968, 'learning_rate': 1.8196948682385578e-05, 'epoch': 0.18030513176144244}\n",
      "{'loss': 0.0031, 'grad_norm': 0.025461403653025627, 'learning_rate': 1.8058252427184467e-05, 'epoch': 0.1941747572815534}\n",
      "{'loss': 0.0153, 'grad_norm': 15.94615650177002, 'learning_rate': 1.791955617198336e-05, 'epoch': 0.20804438280166435}\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Как можно увидеть уже спустя 1 эпоху все eval метрики больше 0.99.",
   "id": "77f2ee2c56133844"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
